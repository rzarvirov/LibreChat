# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true

# Custom interface configuration
interface:
  # Privacy policy settings
  #privacyPolicy:
  #  externalUrl: 'https://aibuddy.one/privacy-policy'
  #  openNewTab: true

  # Terms of service
  termsOfService:
    externalUrl: 'https://aibuddy.one/tos'
    openNewTab: true
    modalAcceptance: false
    useLocalization: true

  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: false
  prompts: false
  bookmarks: false
  multiConvo: false
  agents: true

# Example Registration Object Structure (optional)
registration:
  socialLogins: ['github', 'google', 'yandex', 'discord', 'openid', 'facebook']
  # allowedDomains:
  # - "gmail.com"

# speech:
#   tts:
#     openai:
#       url: ''
#       apiKey: '${TTS_API_KEY}'
#       model: ''
#       voices: ['']

#  
#   stt:
#     openai:
#       url: ''
#       apiKey: '${STT_API_KEY}'
#       model: ''

# rateLimits:
#   fileUploads:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for file uploads per user
#   conversationsImport:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user

# Example Actions Object Structure
actions:
  allowedDomains:
    - "swapi.dev"
    - "librechat.ai"
    - "google.com"

# Example MCP Servers Object Structure
#mcpServers:
#  everything:
    # type: sse # type can optionally be omitted
#    url: http://localhost:3001/sse
#  puppeteer:
#    type: stdio
#    command: npx
#    args:
#      - -y
#      - "@modelcontextprotocol/server-puppeteer"
#  filesystem:
    # type: stdio
#    command: npx
#    args:
#      - -y
#      - "@modelcontextprotocol/server-filesystem"
#      - /home/user/LibreChat/
#    iconPath: /home/user/LibreChat/client/public/assets/logo.svg
#  mcp-obsidian:
#    command: npx
#    args:
#      - -y
#      - "mcp-obsidian"
#      - /path/to/obsidian/vault

# Definition of custom endpoints
endpoints:
  # assistants:
  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`
  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates
  #   timeoutMs: 180000  # Timeout for assistant operations
  #   # Should only be one or the other, either `supportedIds` or `excludedIds`
  #   supportedIds: ["asst_supportedAssistantId1", "asst_supportedAssistantId2"]
  #   # excludedIds: ["asst_excludedAssistantId"]
  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).
  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`
  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature
  #   retrievalModels: ["gpt-4-turbo-preview"]
  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  #   capabilities: ["code_interpreter", "retrieval", "actions", "tools", "image_vision"]
  # agents:
  #   (optional) Maximum recursion depth for agents, defaults to 25
  #   recursionLimit: 50
  #   (optional) Disable the builder interface for agents
  #   disableBuilder: false
  #   (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  #   capabilities: ["execute_code", "file_search", "actions", "tools"]
  custom:
    # DeepSeek Example
    - name: 'Deepseek'
      apiKey: '${DEEPSEEK_API_KEY}'
      baseURL: 'https://api.deepseek.com/v1'
      models:
        default: ['deepseek-chat', 'deepseek-reasoner']
        fetch: false
      titleConvo: true
      titleModel: 'deepseek-chat'
      modelDisplayLabel: 'Deepseek'

    # XAI Example
    - name: "xai"
      apiKey: "${XAI_API_KEY}"
      baseURL: "https://api.x.ai/v1"
      models:
        default: ["grok-2-latest", "grok-2-vision-latest"]
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "grok-2-latest"
      summarize: false
      summaryModel: "grok-2-latest"
      forcePrompt: false
      modelDisplayLabel: "Grok"

    # Mistral AI Example
    - name: 'Mistral'
      apiKey: '${MISTRAL_API_KEY}'
      baseURL: 'https://api.mistral.ai/v1'
      models:
        default: ['mistral-small-latest', 'mistral-large-latest', 'pixtral-large-latest', 'codestral-latest', 'pixtral-12b-2409']
        fetch: false
      titleConvo: true
      titleModel: 'mistral-small-latest'
      modelDisplayLabel: 'Mistral'
      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']

    # Groq Example
    - name: 'groq'
      apiKey: '${GROQ_API_KEY}'
      baseURL: 'https://api.groq.com/openai/v1/'
      models:
        default:
          [
            'gemma2-9b-it',
            'llama-3.3-70b-versatile',
            'llama-3.1-8b-instant',
            'llama-guard-3-8b',
            'llama3-70b-8192',
            'llama3-8b-8192'
          ]
        fetch: false
      titleConvo: true
      titleModel: 'llama-3.3-70b-versatile'
      modelDisplayLabel: 'Groq'

    # OpenRouter Example
    - name: 'OpenRouter'
      apiKey: '${OPENROUTER_KEY}'
      baseURL: 'https://openrouter.ai/api/v1'
      models:
        default: ['meta-llama/llama-3-70b-instruct']
        fetch: true
      titleConvo: true
      titleModel: 'meta-llama/llama-3-70b-instruct'
      dropParams: ['stop']
      modelDisplayLabel: 'OpenRouter'

    # Portkey AI Example
    #- name: "Portkey"
    #  apiKey: "dummy"  
    #  baseURL: 'https://api.portkey.ai/v1'
    #  headers:
    #      x-portkey-api-key: '${PORTKEY_API_KEY}'
    #      x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'
    #  models:
    #      default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']
    #      fetch: true
    #  titleConvo: true
    #  titleModel: 'current_model'
    #  summarize: false
    #  summaryModel: 'current_model'
    #  forcePrompt: false
   #   modelDisplayLabel: 'Portkey'
   #   iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf
# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5
#       fileSizeLimit: 10  # Maximum size for an individual file in MB
#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true  # Disables file uploading to the OpenAI endpoint
#     default:
#       totalSizeLimit: 20
#     YourCustomEndpointName:
#       fileLimit: 2
#       fileSizeLimit: 5
#   serverFileSizeLimit: 100  # Global server file size limit in MB
#   avatarSizeLimit: 2  # Limit for user avatar image size in MB
# See the Custom Configuration Guide for more information on Assistants Config:
# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint